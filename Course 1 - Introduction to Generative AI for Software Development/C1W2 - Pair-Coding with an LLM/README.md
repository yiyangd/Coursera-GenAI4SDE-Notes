### 1. Transformers and code (3 minutes)
### 2. Generating code with chatbots (8 minutes)
### 3. Iterative prompting (4 minutes)
### 4. Giving the LLM feedback (4 minutes)

#### Quiz 1. 
Q1. Which of the following software development tasks can an LLM assist with? Select all correct answers.

- [x] Suggesting packages or algorithms to use to complete a task. 
  - LLMs have encoded broad understanding of computer science and programming languages during their training, and can therefore suggest packages or algorithms that can solve a particular task or problem. 
- [x] Debugging errors
  - LLMs are able to use the artificial understanding of programming they developed in their training to understand the error messages produced by compilers or interpreters, analyze the code that produces the errors, and suggest edits to fix the code.
- [x] Writing documentation 
  - LLMs are able to use the artificial understanding of programming they developed in their training to analyze code, understand it’s intent, and write useful comments to explain how it works.
- [x] Managing dependencies 

Q2. How could you use your expertise as a software developer to improve the following prompt?

“Write a C# function to find the square root of a number?”


- [ ] Define square root for the LLM
- [ ] Provide the model with the assembly code required to complete this task
- [ ] Include the number that you want to find the square root of in the prompt
  - Your goal is to write code that can find the square root of any number, so including one example would not be very useful. 
- [x] Ask for a method rather than a function since this is the language-specific terminology that C# uses
  - If you use your own expertise to guide the LLM, for example by using language-specific terminology in your prompts, this can guide the LLM to a better output.

Q3. You are building a data visualization dashboard in Python and working with an LLM to implement to code. Your first attempt at a prompt is the following:

“Write code for a data dashboard in Python.”

Which of the following details could you add to your prompt to improve the output of your pair-coding work? Select all correct answers.

- [x] Letting the LLM know which web framework you want to use 
  - Providing specific details about which software packages and libraries you want to use will always help the LLM write code that is specific to your needs.

- [x] Providing a detailed description of what you would like the dashboard charts to look like 
  - LLMs can take descriptions of charts, like colors and shapes to use, chart type, font size etc., and implement them in code.

- [x] Including a sample of the data you want to visualize
  - Giving context to the LLM about the data you will be working with will help it write code specifically for your dataset. 

- [ ] Sharing your personal password for accessing the backend database with the LLM

Q4. You can trust that the code generated by an LLM will always work exactly as you want it to.
- [ ] True
- [x] False
  - LLM-generated code can include many errors, like hallucinated parameter values, using deprecated libraries, or carrying out a slightly different procedure than you intended. You should always test generated code thoroughly to confirm that it behaves as you expect before sharing with others or using it in production.

Q5. You are working with an LLM to develop an algorithm to calculate the moving average of a company’s stock price over time. The code that the LLM generates after your initial prompt doesn’t include any error handling. 

What should you do to get the LLM to include error handling in the code? Select all correct answers.

- [x] Follow up with a clear instruction to include error handling in the code
  - Providing really specific in instructions in your follow-up feedback will help the LLM write the code that you want with the error handling included.
- [ ] Hit the “try again” button on the chatbot interface to resend your prompt and see if the model will include error handling
- [ ] Start a new chat with a smarter LLM and try your prompt again
- [x] Follow up with a description of the type of error you’d like to handle, for example missing data.
  - Describing the kind of error you’d like to handle will help the model write the required error handling code for you.
### 5. Assigning the LLM a role (5 minutes)
### 6. Leveling up with multiple roles (2 minutes)
### 7. Expert roles for specialized knowledge (4 minutes)
### 8. LLM best practices (4 minutes)
### Lab. Apply Prompting 
#### Quiz 2. 
Q1. What is the benefit of assigning a specific 'role' to an LLM in your prompts?
- [ ] It restricts the model to simple tasks. 
- [ ] It makes the responses less accurate. 
- [x] It helps guide the AI’s tone, level of detail, and perspective. 
  - Specifying a role for the LLM effectively guides its responses, ensuring the tone, level of detail, and perspective are aligned with the user’s expectations and needs, enhancing the relevance and utility of the information provided.
- [ ] It limits the model's capabilities. 

Q2. You use the following prompt to analyze a database application:

“As an expert in software architecture, critique my database code and give me suggestions for improvement.”

Which of the following items is the LLM most likely to address in its response?

- [ ] Test cases to check the code functions properly. 

- [x] Suitability of the design pattern used in the code. 
  - The suitability of design patterns is most aligned with software architecture and design considerations, and would more likely be addressed by an LLM acting as an expert in software architecture.
- [ ] Vulnerabilities like SQL injection. 
- [ ] Redundancies affecting performance. 

Q3. You should always expect an LLM to return the code you need after a single prompt.

- [ ] True

- [x] False
- You will generally achieve better results when writing code with LLMs by iterating on any code that the model writes with specific feedback and ongoing requests for refinement and improvement.

Q4. Which prompting best practices are being used in the following prompt? Select all correct answers.

“I’m working on an E-commerce application that uses a sqlite database as the backend and SQLAlchemy to execute queries. I’ll be working with a college intern on this code base in the upcoming summer break. Working as a friendly coding mentor for undergraduates, write clear documentation that will help the intern learn how the code works.”

- [ ] Give feedback

- [x] Be specific
  - The prompt includes technical detail about the context of the project, the Python libraries being used, and the intended audience of the code. All of these specific details will help the LLM write the code for the intern.

- [x] Assign a role
  - The prompt assigns the role of “friendly code mentor for undergraduates” to help the LLM understand how to write the documentation for the summer intern.

- [ ] Request an expert opinion
  - Although the prompt assigns a role to the LLM, it isn’t specifying a specific expertise or request for feedback on the work done so far.

Q5. Which of the following prompts would be most likely to produce matplotlib code to generate an interactive pie chart for a website dashboard?
- [ ] Create a pie chart for a website
- [x] You are an expert in building interactive dashboards for websites with deep familiarity of the matplotlib library in python. Create an interactive piechart that will be included in a website dashboard.
  - This prompt includes important details, like the fact the piechart will be hosted on a website and should be interactive, assigns an expert role and specifies a speciality in matplotlib, so this prompt would be very likely to result in the code you want.
- [ ] As an expert in interactive dashboard development, create a piechart visualization in python
- [ ] Create an interactive piechart for a website dashboard


